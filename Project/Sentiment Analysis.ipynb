{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "import fa2\n",
    "import math\n",
    "import community\n",
    "import matplotlib.cm as cm\n",
    "from __future__ import division\n",
    "import matplotlib.image as mpimg\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "import io\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "# Rendering Parameters\n",
    "title_font = {'family': 'sans-serif',\n",
    "        'color':  '#000000',\n",
    "        'weight': 'normal',\n",
    "        'size': 16,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading\n",
    "dict_to_compare = {}\n",
    "newfile = io.open(\"Data_Set_S1.txt\", mode=\"r\", encoding=\"utf-8\")\n",
    "count = 0\n",
    "for row in newfile:\n",
    "    if count < 4:\n",
    "        count +=1\n",
    "        continue\n",
    "        \n",
    "    string = row.split(\"\\t\")\n",
    "    dict_to_compare[string[0]] = float(string[2])\n",
    "\n",
    "def happiness(dict_of_tokens,dict_to_compare):\n",
    "    #dict_of_tokens is the tokenized dictionary with their count (token: count)\n",
    "    #dict_to_compare is a dictionary that contains word as key and the averaged_happiness_weight as value\n",
    "    #Return 0 if no tokens\n",
    "    if len(dict_of_tokens)==0:\n",
    "        return 0\n",
    "    #Sum of token frequency multiplied with the averaged_happiness_weight as in (1) from the paper[Dodds, 2011]\n",
    "    keys = [key for key in dict_of_tokens if key in dict_to_compare.keys()]\n",
    "    #Normalization can only be calculated after keys since \"for which we have an estimate of average happiness\"[Dodds, 2011] applies\n",
    "    normalization = sum(dict_of_tokens[key] for key in keys)\n",
    "    #Return 0 if no word is present in dict_to_compare\n",
    "    if normalization==0:\n",
    "        return 0\n",
    "    sums = sum(dict_to_compare[key]*dict_of_tokens[key] for key in keys)\n",
    "    return sums/normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "moviereviews = {}\n",
    "moviesentement = {}\n",
    "for filename in os.listdir(\"aclImdb/test\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        text = re.findall(\"urls_(\\w*).txt\",filename)\n",
    "        with open(\"aclImdb/test/\"+filename) as file:\n",
    "            for idx,line in enumerate(file):\n",
    "                ID = re.findall(\"http://www.imdb.com/title/(\\w*)/usercomments\",line)\n",
    "                moviereviews[(idx,\"test/\"+text[0])] = ID[0]\n",
    "                moviesentement[ID[0]] = [0,0]\n",
    "for filename in os.listdir(\"aclImdb/train\"):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        text = re.findall(\"urls_(\\w*).txt\",filename)\n",
    "        with open(\"aclImdb/train/\"+filename) as file:\n",
    "            text = re.findall(\"urls_(\\w*).txt\",filename)\n",
    "            for idx,line in enumerate(file):\n",
    "                ID = re.findall(\"http://www.imdb.com/title/(\\w*)/usercomments\",line)\n",
    "                moviereviews[(idx,\"train/\"+text[0])] = ID[0]\n",
    "                moviesentement[ID[0]] = [0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done with 0.0% in the corresponding folder train/unsup.\n",
      "Done with 10.0% in the corresponding folder train/unsup.\n",
      "Done with 20.0% in the corresponding folder train/unsup.\n",
      "Done with 30.0% in the corresponding folder train/unsup.\n",
      "Done with 40.0% in the corresponding folder train/unsup.\n",
      "Done with 50.0% in the corresponding folder train/unsup.\n",
      "Done with 60.0% in the corresponding folder train/unsup.\n",
      "Done with 70.0% in the corresponding folder train/unsup.\n",
      "Done with 80.0% in the corresponding folder train/unsup.\n",
      "Done with 90.0% in the corresponding folder train/unsup.\n",
      "Done with 0.0% in the corresponding folder train/pos.\n",
      "Done with 10.0% in the corresponding folder train/pos.\n",
      "Done with 20.0% in the corresponding folder train/pos.\n",
      "Done with 30.0% in the corresponding folder train/pos.\n",
      "Done with 40.0% in the corresponding folder train/pos.\n",
      "Done with 50.0% in the corresponding folder train/pos.\n",
      "Done with 60.0% in the corresponding folder train/pos.\n",
      "Done with 70.0% in the corresponding folder train/pos.\n",
      "Done with 80.0% in the corresponding folder train/pos.\n",
      "Done with 90.0% in the corresponding folder train/pos.\n",
      "Done with 0.0% in the corresponding folder train/neg.\n",
      "Done with 10.0% in the corresponding folder train/neg.\n",
      "Done with 20.0% in the corresponding folder train/neg.\n",
      "Done with 30.0% in the corresponding folder train/neg.\n",
      "Done with 40.0% in the corresponding folder train/neg.\n",
      "Done with 50.0% in the corresponding folder train/neg.\n",
      "Done with 60.0% in the corresponding folder train/neg.\n",
      "Done with 70.0% in the corresponding folder train/neg.\n",
      "Done with 80.0% in the corresponding folder train/neg.\n",
      "Done with 90.0% in the corresponding folder train/neg.\n",
      "Done with 0.0% in the corresponding folder test/neg.\n",
      "Done with 10.0% in the corresponding folder test/neg.\n",
      "Done with 20.0% in the corresponding folder test/neg.\n",
      "Done with 30.0% in the corresponding folder test/neg.\n",
      "Done with 40.0% in the corresponding folder test/neg.\n",
      "Done with 50.0% in the corresponding folder test/neg.\n",
      "Done with 60.0% in the corresponding folder test/neg.\n",
      "Done with 70.0% in the corresponding folder test/neg.\n",
      "Done with 80.0% in the corresponding folder test/neg.\n",
      "Done with 90.0% in the corresponding folder test/neg.\n",
      "Done with 0.0% in the corresponding folder test/pos.\n",
      "Done with 10.0% in the corresponding folder test/pos.\n",
      "Done with 20.0% in the corresponding folder test/pos.\n",
      "Done with 30.0% in the corresponding folder test/pos.\n",
      "Done with 40.0% in the corresponding folder test/pos.\n",
      "Done with 50.0% in the corresponding folder test/pos.\n",
      "Done with 60.0% in the corresponding folder test/pos.\n",
      "Done with 70.0% in the corresponding folder test/pos.\n",
      "Done with 80.0% in the corresponding folder test/pos.\n",
      "Done with 90.0% in the corresponding folder test/pos.\n"
     ]
    }
   ],
   "source": [
    "stopwordslist = set(stopwords.words('english'))\n",
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "paths = [\"train/unsup\",\"train/pos\",\"train/neg\",\"test/neg\",\"test/pos\"]\n",
    "scores = []\n",
    "for path in paths:\n",
    "    done = len(os.listdir(\"aclImdb/\"+path))\n",
    "    for idx,filename in enumerate(os.listdir(\"aclImdb/\"+path)):\n",
    "        file = io.open(\"aclImdb/\"+path+\"/\"+filename, mode=\"r\", encoding=\"utf-8\")\n",
    "        string = file.readlines()[0]\n",
    "        w = re.findall(r'@\\w*', string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        w = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+[\\/\\w+]*', string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        w = re.findall(\"<[^>]*>\",string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        string = re.sub(r'\\d+', '', string)\n",
    "        string = string.lower()\n",
    "        filtered = tokenizer.tokenize(string)\n",
    "        filtered = [w for w in filtered if w not in stopwordslist]\n",
    "        review = Counter(filtered)\n",
    "        score = happiness(review,dict_to_compare)\n",
    "        moviesentement[moviereviews[(idx,path)]][0] += 1\n",
    "        moviesentement[moviereviews[(idx,path)]][1] += score\n",
    "        scores.append(score)\n",
    "        if idx/done*100%10==0:\n",
    "            print(\"Done with {0}% in the corresponding folder {1}.\".format(idx/done*100,path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sentiment.txt', 'w') as file:\n",
    "     file.write(json.dumps(moviesentement))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#---------------------\n",
    "# HISTOGRAM FUNCTION FOR CONTINUES VALUES\n",
    "#---------------------\n",
    "\n",
    "def histogramCont(degrees,nb_bins):\n",
    "    # Computing Bins\n",
    "    min_bin = np.amin(degrees)\n",
    "    max_bin = np.amax(degrees)\n",
    "    \n",
    "    #Hist\n",
    "    hist, bin_edges = np.histogram(degrees,bins = nb_bins+1)\n",
    "    return hist, bin_edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Blue = \"#232066\"\n",
    "nbins= 50\n",
    "# Get the histograms\n",
    "hist, bins = histogramCont(scores,nbins)\n",
    "plt.figure(figsize = (15,6))\n",
    "plt.bar(bins[:-1], hist, 1/nbins, color=Blue, label = \"Sentiment Score of Movie Reviews\") #0 exlcuded due to no sentiment\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Number of occurences')\n",
    "plt.suptitle('Sentiment distribution', fontsize=16)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print \"Average of average weighted happiness in review: \" + str(np.mean(scores))\n",
    "print \"Standard deviation of average weighted happiness in review: \" + str(np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "positiveReviews = []\n",
    "negativeReviews = []\n",
    "mu = np.mean(scores)\n",
    "sig = np.std(scores)\n",
    "scores = []\n",
    "for path in paths:\n",
    "    done = len(os.listdir(\"aclImdb/\"+path))\n",
    "    for idx,filename in enumerate(os.listdir(\"aclImdb/\"+path)):\n",
    "        file = io.open(\"aclImdb/\"+path+\"/\"+filename, mode=\"r\", encoding=\"utf-8\")\n",
    "        string = file.readlines()[0]\n",
    "        w = re.findall(r'@\\w*', string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        w = re.findall('https?://(?:[-\\w.]|(?:%[\\da-fA-F]{2}))+[\\/\\w+]*', string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        w = re.findall(\"<[^>]*>\",string)\n",
    "        for i in range(0, len(w)):\n",
    "            string = string.replace(w[i], \"\")\n",
    "        string = re.sub(r'\\d+', '', string)\n",
    "        string = string.lower()\n",
    "        filtered = tokenizer.tokenize(string)\n",
    "        filtered = [w for w in filtered if w not in stopwordslist]\n",
    "        review = Counter(filtered)\n",
    "        score = happiness(review,dict_to_compare)\n",
    "        if score <=(mu-2*sig):\n",
    "            negativeReviews=np.concatenate((negativeReviews,filtered))\n",
    "        elif score>=(mu+2*sig):\n",
    "            positiveReviews = np.concatenate((positiveReviews,filtered))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
